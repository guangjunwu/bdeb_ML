{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation de Modele selon des paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectif\n",
    "* Prédire l'espece d'une fleur iris en utilisant KNN avec K variable\n",
    "* Trouver la valeur appropriée de K\n",
    "* Obtenir le modèle qui généralise correctement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train et test sur tout le dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apprentissage du modele sur tout le dataset.\n",
    "* Effectur le Test du modele sur le meme dataset, \n",
    "* Evaluer et comparer la classe predite avec la vraie classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Data shape: \n",
      "(150, 4)\n",
      "Iris Target shape: \n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import neighbors, datasets, metrics\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Lire iris data dans un DataFrame\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "print(\"Iris Data shape: \")\n",
    "print(iris.data.shape)\n",
    "print(\"Iris Target shape: \")\n",
    "print(iris.target.shape)\n",
    "\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "#targetNames = iris.target_names\n",
    "# str(iris)\n",
    "#irisDF = pd.DataFrame(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* utiliser KNN avec K = 50 par exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 49,  1],\n",
       "       [ 0,  1, 49]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantier le modele\n",
    "k_neighbors = 15\n",
    "clf = neighbors.KNeighborsClassifier(k_neighbors, weights='uniform')\n",
    "# Effectuer l'apprentissage du model sur tout le dataset\n",
    "clf.fit(X, Y)\n",
    "# predire la réponse pour les observations dans X, test du model\n",
    "confusion_matrix(clf.predict(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stocker les réponses prédites dans y_pred\n",
    "y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Determiner un metrique tel que Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98666666666666669"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrique d'évaluation - Accuracy de classification\n",
    "\n",
    "metrics.accuracy_score(Y, y_pred)\n",
    "\n",
    "#conclusion ! Est ce qu'on a training accuracy ou testing accuracy ?\n",
    "#\n",
    "# puisqu'on utilise le meme data pour training et testing, il n'y pas vraiement de testing, \n",
    "# donc on obtient a training accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* utiliser KNN avec K = 1 maintenant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculer Accuracy\n",
    "# instantier le modele\n",
    "k_neighbors = 1\n",
    "clf = neighbors.KNeighborsClassifier(k_neighbors, weights='uniform')\n",
    "clf.fit(X, Y)\n",
    "metrics.accuracy_score(Y, clf.predict(X))\n",
    "#conclusion: est ce qu'on a un problème avec cette approche ?\n",
    "# puisque K=1 et on teste sur le training data, l'accuracy est egale a 1. On est dans over fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation procedure #2: Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split du dataset en deux ensemble:  training set et testing set.\n",
    "* apprentissage du modele sur le training set.\n",
    "* Test du modele sur le testing set \n",
    "* Evaluer le modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (90, 4) (60, 4) (90,) (60,)\n",
      "First element:  [ 6.2  2.9  4.3  1.3] [ 5.8  2.7  5.1  1.9] 1 2\n"
     ]
    }
   ],
   "source": [
    "#utiliser la fonction train_test_split avec taille test de 40% sans random_state\n",
    "# Utiliser X_train, X_test, y_train, y_test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris.data, iris.target, test_size=0.40)\n",
    "\n",
    "#afficher les différentes shape\n",
    "print \"Shape: \", X_train.shape, X_test.shape, Y_train.shape, Y_test.shape\n",
    "\n",
    "#afficher le premier element de chaque ensemble\n",
    "print \"First element: \", X_train[1,:], X_test[1,:], Y_train[1,], Y_test[1,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Effet du paramètre random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* refaire le meme avec random_state = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (90, 4) (60, 4) (90,) (60,)\n",
      "First element:  [ 5.6  3.   4.1  1.3] [ 5.7  3.8  1.7  0.3] 1 0\n"
     ]
    }
   ],
   "source": [
    "# Utiliser X_train, X_test, y_train, y_test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris.data, iris.target, test_size=0.40, random_state=4)\n",
    "\n",
    "#afficher les différentes shape\n",
    "print \"Shape: \", X_train.shape, X_test.shape, Y_train.shape, Y_test.shape\n",
    "\n",
    "#afficher le premier element de chaque ensemble\n",
    "print \"First element: \", X_train[1,:], X_test[1,:], Y_train[1,], Y_test[1,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Effectuer apprentissage avec K=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94999999999999996"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Etape 1: split en traning et test avec random state = 4\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris.data, iris.target, test_size=0.40, random_state=4)\n",
    "\n",
    "#Etape 2: faire l'apprentissage\n",
    "clf = neighbors.KNeighborsClassifier(1, weights='uniform')\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "#Etape 3: faire le test du modèle avec l'ensemble d'apprentissage\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#Etape 4: determiner accuracy\n",
    "metrics.accuracy_score(Y_test, y_pred)\n",
    "\n",
    "#Est ce que vous avez une training accuracy ou testing accuracy ?\n",
    "# Puisqu'on a separer le training et le testing data, on obtient ici un testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Effectuer apprentissage avec K=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.983333333333\n",
      "Shape:  (90, 4) (60, 4) (90,) (60,)\n",
      "First element:  [ 5.6  3.   4.1  1.3] [ 5.7  3.8  1.7  0.3] 1 0\n"
     ]
    }
   ],
   "source": [
    "#Etape 1: split en traning et test avec random state = 4 \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris.data, iris.target, test_size=0.40, random_state=4)\n",
    "\n",
    "#Etape 2: faire l'apprentissage\n",
    "clf = neighbors.KNeighborsClassifier(15, weights='uniform')\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "#Etape 3: faire le test du modèle avec l'ensemble d'apprentissage\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#Etape 4: determiner accuracy\n",
    "print metrics.accuracy_score(Y_test, y_pred)\n",
    "\n",
    "print \"Shape: \", X_train.shape, X_test.shape, Y_train.shape, Y_test.shape\n",
    "print \"First element: \", X_train[1,:], X_test[1,:], Y_train[1,], Y_test[1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Comparer avec l'approche où un seul ensemble de données\n",
    "## \n",
    "## Le cas de K=1, c'est overfitting.\n",
    "## Pour le dataset iris, le fait de separer en training et testing n'affecte pas le resultat d'apprentissage.\n",
    "#Votre conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction avec un echantillon out-of-sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On prend un echantillon completement inconnu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantier le modele avec K égale à valeur optimale (comment?)\n",
    "clf = neighbors.KNeighborsClassifier(15, weights='uniform')\n",
    "\n",
    "#Effectuer l'apprentissage avec X et y  (ne pas prendre X_train et y_train)\n",
    "clf.fit(X,Y)\n",
    "\n",
    "#Faire une prediction avec l'échantillon [3,5,4,5]\n",
    "#print X #\n",
    "clf.predict([[3,5,4,5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
