{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulation 1 : Préparation des données pour évaluer les modèles \n",
    "#### Objectif : \n",
    "Pour évaluer les modèles, vous devez les construire avec des données et de les tester sur d'autres données. Cette vous montrera comment préparer les deux ensembles de données. Le package recommenderlab contient des outils prédéfinis qui aident dans cette tâche.\n",
    "\n",
    "L'objectif est de définir deux ensembles de données, qui sont les suivants :\n",
    "- Jeu d’apprentissage \n",
    "- Jeu de test\n",
    "Évaluer le modèle en comparant les ratings prédits par le modèle avec leurs vrais valeurs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Charger les données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Validation croisé k-fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Préparer les données de test pour l’évaluation\n",
    "\n",
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulation 2 :  Évaluer des ratings \n",
    "Nous devons définir le modèle à évaluer. Par exemple, nous pouvons évaluer le Item-Based Recommender.\n",
    "Nous avons besoin de spécifier le nom du modèle et la liste de ses paramètres. Si nous utilisons leurs valeurs par défaut, alors il est NULL :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construire le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### nous voulons recommander, par exemple, 10, même si on n'a pas besoin d'utiliser ce paramètre dans l'évaluation :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Construire la matrice avec les ratings prédit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'realRatingMatrix'"
      ],
      "text/latex": [
       "'realRatingMatrix'"
      ],
      "text/markdown": [
       "'realRatingMatrix'"
      ],
      "text/plain": [
       "[1] \"realRatingMatrix\"\n",
       "attr(,\"package\")\n",
       "[1] \"recommenderlab\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Métrique d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulation 3 Évaluser la recommandation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Evaluer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBCF run fold/sample [model time/prediction time]\n",
      "\t 1  [0.431sec/0.058sec] \n",
      "\t 2  [0.497sec/0.057sec] \n",
      "\t 3  [0.483sec/0.056sec] \n",
      "\t 4  [0.505sec/0.05sec] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'evaluationResults'"
      ],
      "text/latex": [
       "'evaluationResults'"
      ],
      "text/markdown": [
       "'evaluationResults'"
      ],
      "text/plain": [
       "[1] \"evaluationResults\"\n",
       "attr(,\"package\")\n",
       "[1] \"recommenderlab\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-  Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Coubre ROC, Recall & Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ROC\n",
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Recall & Precision \n",
    "# Votre code ici"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
